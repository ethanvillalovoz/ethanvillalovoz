<!--
### 👋 Hi, I'm Ethan Villalovoz
- 🎓 Senior at Washington State University, aspiring researcher in Robotics & AI.
- 🤖 Passionate about advancing robot learning, multimodal systems, and reinforcement learning.
- 🌟 Research focus: Creating interactive, socially adaptive robots that enhance human-AI collaboration.
- 💻 Find more about me at [ethanvillalovoz.github.io](https://ethanvillalovoz.github.io/).

I want you to create a detailed write up explaining the problem you have addressed, approach we took, the challenges we faced, and the results we came up. Include code snippets, visualizations and more


CS 6515 – Intro to Graduate Algorithms

CS 7641 – Machine Learning

CS 6476 – Computer Vision

CS 7650 – Natural Language Processing

CS 7638 – AI Techniques for Robotics

CS 7637 – Knowledge-Based AI

CS 7642 – Reinforcement Learning

CS 7643 – Deep Learning

ISYE 6420 – Bayesian Statistics

CS 7632 – Game AI ✅ (Best aligned with real-time autonomy, sim environments, and agent planning)

---
-->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=180&section=header&text=Hi%2C%20I'm%20Ethan%20Villalovoz&fontSize=40&fontAlign=50&fontColor=ffffff"/>
</p>

<!--
<h3 align="center">AI/Robotics Researcher • CS Grad @ WSU • Open to Work</h3>
-->

<!--
<p align="center">
  <a href="https://ethanvillalovoz.github.io">Portfolio Website</a> • 
  <a href="mailto:ethanvillalovoz@gmail.com">Email</a> • 
  <a href="https://www.linkedin.com/in/ethanvillalovoz">LinkedIn</a>
</p>
-->

---

### 👋 About Me

I recently graduated with a B.S. in Computer Science and a minor in Mathematics from Washington State University. I’ve conducted research in AI, robotics, and machine learning at institutions like Carnegie Mellon University (HARP Lab), Oregon State University, and WSU. I’ve also interned at Google as a STEP intern, where I worked on scalable internal tools using C++, SQL, and HTML.

---

### 🛠️ Languages & Tools

<p align="center">
  <img src="https://skillicons.dev/icons?i=python,cpp,pytorch,tensorflow,ros,jupyter,git,html,sql,github" />
</p>

---

<!--
### 📊 GitHub Stats

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=ethanvillalovoz&show_icons=true&theme=github_dark" width="48%" />
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=ethanvillalovoz&layout=compact&theme=github_dark&hide=html,css" width="48%" />
</p>

---

Okay. So as you may know I am currently doing side projects while I apply for jobs apps etc. I want to create projects that can make me stand out and appeal to my future PhD Advisor Andrea Bobu. Here are her research interests:

As autonomous agents become increasingly woven into the fabric of society—from self-driving cars to personal robot manipulators to AI assistants—our lab aims to ensure their seamless interaction with people. However, integrating these systems into human-centered environments in a way that aligns with human expectations is a formidable challenge. Specifying human objectives to robots is difficult because these objectives are complex, context-dependent, and inherently subjective. Without the right objectives, autonomous systems may exhibit unexpected or even dangerous behaviors.

Learning these objectives (for instance, as reward functions) has emerged as a popular alternative to manual specification, but it comes with its own set of difficulties: 1) getting the right data to supervise the learning is hard because humans are imperfect, not infinitely queryable, and have unique and changing preferences; 2) the representations we choose to mathematically express human objectives may themselves be wrong, thus preventing us from ever being able to capture desired behaviors; 3) reliably quantifying misalignment—or discrepancies from expected behavior—to ensure system safety remains underexplored.

Our goal is to develop autonomous agents whose behavior aligns with human expectations—whether the human is an expert system designer, a novice end-user, or another AI stakeholder. Our research combines expertise from robotics, deep learning, cognitive psychology, and probabilistic reasoning to develop more aligned, generalizable, and robust learning algorithms.
Asking for the Right Data
Typical methods that learn from human feedback (e.g. RLHF) treat humans as infinitely queryable oracles. However, individual humans have unique and evolving preferences, objectives, and biases that may not be fully reflected in canned internet data. Our research explores ways to effectively learn human objectives from noisy, incomplete, or inconsistent data. We focus on designing algorithms that can extract meaningful information from limited interactions, using structure, simulation, and powerful priors. This allows autonomous systems to better understand and anticipate human needs.

Getting the right data from humans

Interactively Arriving at Shared Task Representations
To act in the world, robots rely on a representation of salient task features: for example, to hand over a cup of coffee, the robot may consider efficiency and cup orientation in its behavior. But if we want robots to act for and with people, their representations must not be just functional but also reflective of what humans care about, i.e. they must be aligned with humans. If they're not, misalignment could lead to unintended and potentially harmful behavior; for example, we saw a robot arm move a coffee cup inches away from a person's face because it lacked an understanding of personal space. Our research focuses on aligning robot representations with humans via interactive processes where robots and humans can find shared task representations.

Interactively arriving at shared representations

Reliably Quantifying Misalignment
A key component of ensuring reliable autonomous systems is the ability to quantify how well a system's behavior aligns with human expectations. An autonomous agent should know when it doesn't know enough, and either ask for help or learn in proportion to how confident it is in its model. Our research aims to develop metrics and methods to detect and correct misalignment, ensuring that autonomous systems behave predictably and safely in diverse situations. This includes exploring probabilistic reasoning and cognitive psychology to understand and mitigate the risks associated with misalignment.

Quantifying misalignment

Check out our TEDxMIT talk on why robots aren't superhuman in our human world to get a sense of our research philosophy!

Here is the project I want to work on
-->

### 🧠 Currently...
- 📝 Applying to full-time AI/ML research roles
- 🎯 Preparing for MS applications (Spring 2026)

Thanks for visiting — feel free to reach out if you want to chat or collaborate!
