<!--
### ğŸ‘‹ Hi, I'm Ethan Villalovoz
- ğŸ“ Senior at Washington State University, aspiring researcher in Robotics & AI.
- ğŸ¤– Passionate about advancing robot learning, multimodal systems, and reinforcement learning.
- ğŸŒŸ Research focus: Creating interactive, socially adaptive robots that enhance human-AI collaboration.
- ğŸ’» Find more about me at [ethanvillalovoz.github.io](https://ethanvillalovoz.github.io/).

I want you to create a detailed write up explaining the problem you have addressed, approach we took, the challenges we faced, and the results we came up. Include code snippets, visualizations and more


CS 6515 â€“ Intro to Graduate Algorithms

CS 7641 â€“ Machine Learning

CS 6476 â€“ Computer Vision

CS 7650 â€“ Natural Language Processing

CS 7638 â€“ AI Techniques for Robotics

CS 7637 â€“ Knowledge-Based AI

CS 7642 â€“ Reinforcement Learning

CS 7643 â€“ Deep Learning

ISYE 6420 â€“ Bayesian Statistics

CS 7632 â€“ Game AI âœ… (Best aligned with real-time autonomy, sim environments, and agent planning)

Whatâ€™s your ideal breakdown of your time in a working week, in terms of hours or % per week spent on meetings, coding, reading papers, etc.?

I recognize that, ideally, we would want our breakdown schedule to be more concrete and dynamic as important deadlines are near. Hence, my response to this question will be a range instead of specific numbers.

1. Coding and Experiemtnation (50% - 60%):
-The majority of work that I will spend during the week is implementing and refactoring code from my project. Not only do I enjoy hands-on work, but I also understand that the cutting-edge forefront of AI takes trial and error to finetune the models. I would want to ensure that any additions, such as optimizing and adding new features, are carefully implemented to give consumers a more satisfying experience using Anthropic's models. Even if it slightly increases user satisfaction, that still impacts me, to be precise, in my coding.

2. Research and Reading Papers (20% - 30%):
-The domain of AI is changing rapidly with the discovery of new technologies. Staying updated on the latest discoveries will help me stay up to date and also help me create new ideas about how the work at Anthropic aligns with and can benefit from these advancements. Ideally, I would want to have the goal of reading 2 to 3 papers a day that can help with my project and also improve my literature knowledge within the area of work.

3. Meetings and Collaborations (10% - 20%):
-While this percentage may be a little higher than expected, I highly value time to allocate for discussions to share ideas and help resolve challenges that I or anyone on the team may have. What I love most about research is the natural collaboration between others. We are the future researchers of the world, and collaborating frequently drives ideas and discoveries much faster and more meaningful. I also consider this time to be spent in formal stand-up meetings, brainstorming, and pair programming time with others. Taking the time to help others overcome roadblocks in their work, and myself is important to me to learn and carry forward efficiently toward the project goal.

4. Documentation and Reflections (5% - 10%):
-During the production, documentation is very important to allow others to understand and utilize the tools you created. If the project is more research-focused, this is no different, but the goal is to document work to allow others to replicate your work. I believe this is important to improve the workflows of any technologies that will be reused. I also believe that it is important to take the time to reflect after a project submission or delivery. Understanding the challenges and what helped to efficiently complete work, I believe, is important to continuously learn and takeaway to be more impactful in the next project. If I find a new technology or effective way to get my work done to enhance the team's productivity, I believe that it is very important to take the time to reflect on it.




Why Anthropic? *
Why do you want to work at Anthropic? (We value this response highly - great answers are often 200-400 words.)

I want to work at Anthropic because I highly resonate with the company's mission of creating artificial intelligence (AI) that can benefit society. I am very passionate about having the opportunity to contribute to cutting-edge technology that can help assist and change many interdisciplinary fields where AI has the root impact to accelerate this goal. I am very fascinated by the current challenges we face in reliable and interpretable systems to create ethical and safe deployment of models. With my current experiences, this field of work aligns with the opportunity to impact the world.

Within my undergraduate experiences, I have followed the theme of working on projects centered on building systems adaptable to humans. While I was at Carnegie Mellon University, my work focused on developing a hierarchical reward learning framework using reinforcement learning to refine the robotic understanding of human corrections. The goal was to enhance robot understanding to help understand human preferences in assistive settings such as a robot helping load a dishwasher. I value the importance of creating systems that adapt in dynamic environments; in this case, I want to join Anthropic to enhance AI agents to be more adaptable to human language and generate responses that agents have learned from the user.

I am very excited about having the opportunity to collaborate on research initiatives. At the very beginning of my undergraduate career, I had the opportunity to engage in many research projects, and I have always wanted to pursue a career that is research-focused. This role aligns with my goals of being able to work on projects with a multidisciplinary team and contribute to impactful work that connects technology to society. For this role, I am very interested in work where I can have the chance to explore new solutions to building and research new ideas to create safe and reliable systems.

What I love about having the opportunity to work at Anthropic is to continuously learn and be curious about the field. This role allows me to further enhance my software engineering skills while still engaging in non-stop learning within AI research. Throughout my academic career, I have been waiting to find the perfect opportunity to be a part of a team that not only prompts innovation but also aims to benefit society. The greatest reward is being able to impact everyone to better their lives. With my passion for AI and a company with a mission, Anthropic is where I want to be.









In one paragraph, provide an example of something meaningful that you have done in line with your values. Examples could include past work, volunteering, civic engagement, community organizing, donations, family support, etc. *

In the final year of my undergraduate degree, I reflect on all the great opportunities I have had to embark on. I am truly thankful; however, I can never thank the people who helped me get there enough. My mentors, friends, and peers have all supported me and helped me get where I am today. Hence, I volunteered as a first-year mentor for incoming computer science students. I understand and have dealt with the transition into college, being in a major that can be very new and challenging to students. I also understand the feeling of being overwhelmed with how to gain experience to be prepared for a future career. Every week, I meet with my mentee to discuss future goals and how I can assist them. For example, one of my students wanted to intern after their first year but didn't know where to apply or how to make an appealing resume. With my assistance, I was able to help them navigate what roles to apply for at top companies, and they have already received a few interviews for roles this upcoming summer. This means a lot to me because it deepens my belief in creating a supportive environment for learning and lifting others to succeed. I want to show and allow others to have experiences that will give them valuable experience and growth in their journeys to make a difference in the world.













Additional Information *
Add a cover letter or anything else you want to share.

Dear Anthropic Team,

I am excited to apply for the position at Anthropic. The company's mission aligns with my passion for creating reliable and interpretable AI systems that can safely and positively impact users and society. I believe my experience in developing hierarchical reward learning systems, optimizing large-scale data pipelines, and working with transformer-based models makes me an excellent candidate to contribute to the company's cutting-edge work.

This past summer, while I was a research assistant at Carnegie Mellon University, my work refined my robotic understanding using Bayesian Inference and large language models (LLMs) to enhance the alignment between robot and human preferences. This experience allowed me to be exposed to reinforcement learning techniques and navigate through complex designs to implement adaptable solutions. Previously, at Google, I gained expertise in optimizing multi-terabyte data workflows. There, I gained experience in map-reduce techniques and, by doing so, reduced workflow runtime by 66%. These experiences shaped my strong foundation in large-scale system optimization and AI solutions.

I am very excited about Anthropic's research culture and collaboration and its commitment to addressing the societal impact of AI. I resonate deeply with the focus on advancing AI that is both scalable and trustworthy. I believe that focusing on these advances will benefit and accelerate other interdisciplinary fields as more people use AI.

Thank you for considering my application. I am eager to contribute my skills to the team and to the mission of building AI systems that benefit society.

Best Regards,
Ethan Villalovoz












AI should serve as a tool for amplifying human capabilities to address the most pressing challenges. We can analyze complex, multimodal data at scale and uncover actionable insights by harnessing AI for applications like climate modeling, sustainable resource management, and assistive technologies. AI must prioritize ethical deployment, ensuring transparency, fairness, and accessibility. It should empower underserved communities, optimize solutions for environmental sustainability, and drive global progress while complementing human expertise, not replacing it. Ultimately, AI should catalyze innovation, enabling humanity to solve problems collaboratively, responsibly, and equitably.

---
-->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=180&section=header&text=Hi%2C%20I'm%20Ethan%20Villalovoz&fontSize=40&fontAlign=50&fontColor=ffffff"/>
</p>

<!--
<h3 align="center">AI/Robotics Researcher â€¢ CS Grad @ WSU â€¢ Open to Work</h3>
-->

<!--
<p align="center">
  <a href="https://ethanvillalovoz.github.io">Portfolio Website</a> â€¢ 
  <a href="mailto:ethanvillalovoz@gmail.com">Email</a> â€¢ 
  <a href="https://www.linkedin.com/in/ethanvillalovoz">LinkedIn</a>
</p>
-->

---

### ğŸ‘‹ About Me

I recently graduated with a B.S. in Computer Science and a minor in Mathematics from Washington State University. Iâ€™ve conducted research in AI, robotics, and machine learning at institutions like Carnegie Mellon University (HARP Lab), Oregon State University, and WSU. Iâ€™ve also interned at Google as a STEP intern, where I worked on scalable internal tools using C++, SQL, and HTML.

---

### ğŸ› ï¸ Languages & Tools

<p align="center">
  <img src="https://skillicons.dev/icons?i=python,cpp,pytorch,tensorflow,ros,jupyter,git,html,sql,github" />
</p>

---

<!--
### ğŸ“Š GitHub Stats

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=ethanvillalovoz&show_icons=true&theme=github_dark" width="48%" />
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=ethanvillalovoz&layout=compact&theme=github_dark&hide=html,css" width="48%" />
</p>

---

Okay. So as you may know I am currently doing side projects while I apply for jobs apps etc. I want to create projects that can make me stand out and appeal to my future PhD Advisor Andrea Bobu. Here are her research interests:

As autonomous agents become increasingly woven into the fabric of societyâ€”from self-driving cars to personal robot manipulators to AI assistantsâ€”our lab aims to ensure their seamless interaction with people. However, integrating these systems into human-centered environments in a way that aligns with human expectations is a formidable challenge. Specifying human objectives to robots is difficult because these objectives are complex, context-dependent, and inherently subjective. Without the right objectives, autonomous systems may exhibit unexpected or even dangerous behaviors.

Learning these objectives (for instance, as reward functions) has emerged as a popular alternative to manual specification, but it comes with its own set of difficulties: 1) getting the right data to supervise the learning is hard because humans are imperfect, not infinitely queryable, and have unique and changing preferences; 2) the representations we choose to mathematically express human objectives may themselves be wrong, thus preventing us from ever being able to capture desired behaviors; 3) reliably quantifying misalignmentâ€”or discrepancies from expected behaviorâ€”to ensure system safety remains underexplored.

Our goal is to develop autonomous agents whose behavior aligns with human expectationsâ€”whether the human is an expert system designer, a novice end-user, or another AI stakeholder. Our research combines expertise from robotics, deep learning, cognitive psychology, and probabilistic reasoning to develop more aligned, generalizable, and robust learning algorithms.
Asking for the Right Data
Typical methods that learn from human feedback (e.g. RLHF) treat humans as infinitely queryable oracles. However, individual humans have unique and evolving preferences, objectives, and biases that may not be fully reflected in canned internet data. Our research explores ways to effectively learn human objectives from noisy, incomplete, or inconsistent data. We focus on designing algorithms that can extract meaningful information from limited interactions, using structure, simulation, and powerful priors. This allows autonomous systems to better understand and anticipate human needs.

Getting the right data from humans

Interactively Arriving at Shared Task Representations
To act in the world, robots rely on a representation of salient task features: for example, to hand over a cup of coffee, the robot may consider efficiency and cup orientation in its behavior. But if we want robots to act for and with people, their representations must not be just functional but also reflective of what humans care about, i.e. they must be aligned with humans. If they're not, misalignment could lead to unintended and potentially harmful behavior; for example, we saw a robot arm move a coffee cup inches away from a person's face because it lacked an understanding of personal space. Our research focuses on aligning robot representations with humans via interactive processes where robots and humans can find shared task representations.

Interactively arriving at shared representations

Reliably Quantifying Misalignment
A key component of ensuring reliable autonomous systems is the ability to quantify how well a system's behavior aligns with human expectations. An autonomous agent should know when it doesn't know enough, and either ask for help or learn in proportion to how confident it is in its model. Our research aims to develop metrics and methods to detect and correct misalignment, ensuring that autonomous systems behave predictably and safely in diverse situations. This includes exploring probabilistic reasoning and cognitive psychology to understand and mitigate the risks associated with misalignment.

Quantifying misalignment

Check out our TEDxMIT talk on why robots aren't superhuman in our human world to get a sense of our research philosophy!

Here is the project I want to work on
-->

### ğŸ§  Currently...
- ğŸ“ Applying to full-time AI/ML research roles
- ğŸ¯ Preparing for MS applications (Spring 2026)

Thanks for visiting â€” feel free to reach out if you want to chat or collaborate!
